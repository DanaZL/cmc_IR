{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "import urllib\n",
    "import os\n",
    "import pymorphy2\n",
    "import re\n",
    "from copy import deepcopy\n",
    "import operator\n",
    "import numpy as np\n",
    "\n",
    "RusLem = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def bprint(l, sep = \" \"):\n",
    "    print sep.join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    return u\" \".join(t.strip() for t in visible_texts)\n",
    " \n",
    "\n",
    "#get list of sentences from html pages\n",
    "def prepare_html_pages(html_dir):\n",
    "    html_files = sorted(os.listdir(html_dir))\n",
    "    sentences = []\n",
    "    for filename in html_files:\n",
    "        text = \"\" \n",
    "        with open(html_dir + filename, \"r\") as f:\n",
    "            for line in f:\n",
    "                text += line\n",
    "                \n",
    "        visible_text = text_from_html(text)\n",
    "        sentences += visible_text.strip().split(\".\")\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "\n",
    "#sentences_normaliation\n",
    "def normalization(sentences):\n",
    "    for i, sent in enumerate(sentences):\n",
    "        tokens = re.findall('[\\w]+', sent.strip().lower(), re.U)\n",
    "        sentences[i] = \" \".join([RusLem.parse(token)[0].normal_form for token in tokens])\n",
    "    return sentences\n",
    "\n",
    "\n",
    "#creating forward index {sent_id: list of word} and token_dictionary\n",
    "def create_forward_index(sentences):\n",
    "    forward_index = {}\n",
    "    token_list = set()\n",
    "    for sent_id, sent in enumerate(sentences):\n",
    "        if 1 < len(sent.strip().split()) <= 40:\n",
    "            forward_index[sent_id] = sent.strip().split()\n",
    "            for token in sent.strip().split():\n",
    "                token_list.add(token)\n",
    "        \n",
    "    return forward_index, list(token_list)\n",
    "\n",
    "\n",
    "def calculate_idf(forward_index, token_list):\n",
    "    cnt_sentences = len(forward_index)\n",
    "    token_df = {token:0 for token in token_list}\n",
    "    for tokens in forward_index.values():\n",
    "        for token in tokens:\n",
    "            token_df[token] += 1\n",
    "    token_idf = {token:np.log(cnt_sentences / float(token_df[token])) for token in token_df}\n",
    "    return token_idf\n",
    "\n",
    "def vec_normalization(vector):\n",
    "    return vector / (1.0 * np.sqrt(np.sum(vector**2)))\n",
    "\n",
    "def cos_similarity(vec_1, vec_2):\n",
    "    return np.sum(vec_1 * vec_2) / float(np.sqrt(np.sum(vec_1**2)) * np.sqrt(np.sum(vec_2**2)))\n",
    "\n",
    "def get_tokens_probs(forward_index, token_list):\n",
    "    tokens_cnt = 0\n",
    "    token_probs = {token:0 for token in token_list}\n",
    "    for sent_idx in forward_index.keys():\n",
    "        for token in forward_index[sent_idx]:\n",
    "            token_probs[token] += 1\n",
    "        tokens_cnt += len(forward_index[sent_idx])\n",
    "        \n",
    "    token_probs = {token:token_probs[token] / float(tokens_cnt) for token in token_list}\n",
    "    return token_probs\n",
    "        \n",
    "    \n",
    "class Collection(object):\n",
    "    def __init__(self, htmls_dir=\"./htmls/\"):\n",
    "        self.raw_sentences = prepare_html_pages(htmls_dir)\n",
    "        print len(self.raw_sentences)\n",
    "        self.norm_sentences = normalization(deepcopy(self.raw_sentences))\n",
    "        print len(self.norm_sentences)\n",
    "        self.forward_index, self.token_list = create_forward_index(self.norm_sentences)\n",
    "        print len(self.forward_index)\n",
    "        self.token_idf = calculate_idf(self.forward_index, self.token_list)\n",
    "        self.token_probs = get_tokens_probs(self.forward_index, self.token_list)\n",
    "        \n",
    "    def doc2vec(self, sentence, idf=False):\n",
    "        \"\"\"\n",
    "        Create sentence normalized vector\n",
    "        \"\"\"\n",
    "        vector = [sentence.count(token) for token in self.token_list]\n",
    "#         print sum(vector)\n",
    "        if idf:\n",
    "            vector = [c * np.log(self.token_idf[self.token_list[i]])\n",
    "                      for i, c in enumerate(vector)]\n",
    "            \n",
    "        return np.asarray(vector)\n",
    "        \n",
    "    def sents2vectors(self):\n",
    "        self.simple_vectors = {sent_idx:vec_normalization(\n",
    "                                        self.doc2vec(self.forward_index[sent_idx], idf=False)\n",
    "                                        )\n",
    "                               for sent_idx in self.forward_index.keys()}\n",
    "        \n",
    "        self.idf_vectors = {sent_idx:vec_normalization(\n",
    "                                    self.doc2vec(self.forward_index[sent_idx], idf=True)\n",
    "                                    )\n",
    "                               for sent_idx in self.forward_index.keys()}\n",
    "        \n",
    "    def vec_ranking(self, query):\n",
    "        norm_query = normalization([query])[0]\n",
    "        bprint([norm_query])\n",
    "        query_vec_simple = self.doc2vec(norm_query.strip().split(), idf=False)\n",
    "        query_vec_idf = self.doc2vec(norm_query.strip().split(), idf=True)\n",
    "\n",
    "        rank_simple = {}\n",
    "        rank_tfidf = {}\n",
    "        for sent_idx in self.simple_vectors.keys():\n",
    "            rank_simple[sent_idx] = cos_similarity(query_vec_simple,\n",
    "                                                   self.simple_vectors[sent_idx])\n",
    "            rank_tfidf[sent_idx] = cos_similarity(query_vec_idf,\n",
    "                                                   self.idf_vectors[sent_idx])\n",
    "        \n",
    "        return rank_simple, rank_tfidf\n",
    "    \n",
    "    #lambda - l\n",
    "    def lang_model_ranking(self, query, l=0.7):\n",
    "        norm_query = normalization([query])[0].strip().split(\" \")\n",
    "        bprint(norm_query)\n",
    "        rank = {}\n",
    "        print len(self.token_probs)\n",
    "        for sent_idx in self.forward_index.keys():\n",
    "            rank[sent_idx] = 0\n",
    "            for token in norm_query:\n",
    "                token_document_prob = sum([1 if t == token else 0 \\\n",
    "                                           for t in self.forward_index[sent_idx]])\n",
    "                if token in self.token_probs:\n",
    "                    rank[sent_idx] += (1 - l) * self.token_probs[token] + l * token_document_prob\n",
    "                    if sent_idx == 369:\n",
    "                        print token, self.token_probs[token], token_document_prob\n",
    "                    \n",
    "#                     print token, \n",
    "        return rank\n",
    "            \n",
    "\n",
    "def print_serp(rank, query, sent_cnt = 10):\n",
    "    sorted_rank = sorted(rank.items(), key = operator.itemgetter(1), reverse=True)\n",
    "    print \"Query:\",\n",
    "    bprint([query])\n",
    "    print \"\\n\"\n",
    "    serp = []\n",
    "    \n",
    "    for idx, pair in enumerate(sorted_rank):\n",
    "#         print idx, pair\n",
    "        if idx > sent_cnt:\n",
    "            break\n",
    "        print pair[1], \"\\t\", pair[0], \n",
    "        bprint(collection.forward_index[pair[0]])\n",
    "        print\n",
    "        serp.append(pair[0])\n",
    "    return serp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169\n",
      "1169\n",
      "933\n"
     ]
    }
   ],
   "source": [
    "collection = Collection()\n",
    "collection.sents2vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = u\"В начале XX века немецкий учитель математики, сам того не желая, научил лошадь считать.\"\n",
    "query_2 = u\"Искусственный язык для фантастической вселенной «Звёздный путь» создал профессиональный лингвист\"\n",
    "query_3 = u\"На территории России были обнаружены останки ниппонозаврa, амурозаврa,целурозаврa и другие виды динозавров.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в начало xx век немецкий учитель математика сам тот не желать научить лошадь считать\n",
      "искусственный язык для фантастический вселенная звёздный путь создать профессиональный лингвист\n",
      "на территория россия быть обнаружить останки ниппонозаврa амурозаврa целурозаврa и другой вид динозавр\n"
     ]
    }
   ],
   "source": [
    "rank_simple_1, rank_idf_1 = collection.vec_ranking(query=query_1)\n",
    "rank_simple_2, rank_idf_2 = collection.vec_ranking(query=query_2)\n",
    "rank_simple_3, rank_idf_3 = collection.vec_ranking(query=query_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: В начале XX века немецкий учитель математики, сам того не желая, научил лошадь считать.\n",
      "\n",
      "\n",
      "0.284747398726 \t288 в начало век популярный в сша стать блюз и джаз который сохранять свой господство в музыка до появление рок наш ролл в 1950 х год\n",
      "\n",
      "0.283069258536 \t248 содержание скрыть 1 основной событие 2 главное изобретение 3 использование сочетание xx век в название 4 двадцать век в искусство 5 сантиметр\n",
      "\n",
      "0.283069258536 \t382 также править править вика текст в викитека есть текст по тема документ xx век xx век хронология изобретение\n",
      "\n",
      "0.283069258536 \t552 xxii век править править вика текст в начало xxii век в клингонский общество повсеместно усилиться влияние класс воин\n",
      "\n",
      "0.277350098113 \t766 в многий страна в тот число и в россия в 21 век наблюдаться тенденция к снижение престижность педагогический профессия и как следствие недооценённость учительский труд\n",
      "\n",
      "0.273861278753 \t374 в сша один из крупный киностудия называться xx век фокс\n",
      "\n",
      "0.258198889747 \t780 учитель в образовательный процесс править править вика текст монумент учитель и ученик в росток\n",
      "\n",
      "0.258198889747 \t801 компонента педагогический культура учитель в\n",
      "\n",
      "0.25515518154 \t333 тем не менее в конец хх век инфекционный болезнь впервые в история человечество уступить первенство в качество причина смерть заболевание сердечно сосудистый система и злокачественный новообразование\n",
      "\n",
      "0.246182981959 \t777 тем не менее в результат реформа средний заработный плат учитель в москва с 2010 по 2014 год вырасти на 79\n",
      "\n",
      "0.240771706172 \t292 визуальный культура стать доминировать не только в кино и телевидение но проникнуть в литература в вид комикс\n",
      "\n"
     ]
    }
   ],
   "source": [
    "serp_simple_1 = print_serp(rank_simple_1, query_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: В начале XX века немецкий учитель математики, сам того не желая, научил лошадь считать.\n",
      "\n",
      "\n",
      "0.298656541657 \t655 ганс считать\n",
      "\n",
      "0.240220023117 \t667 другой слово ганс быть действительно феноменально умный лошадь и прекрасно понимать что от он хотеть но конечно ни математика ни немецкий язык он не знать и не понимать\n",
      "\n",
      "0.216234146561 \t382 также править править вика текст в викитека есть текст по тема документ xx век xx век хронология изобретение\n",
      "\n",
      "0.183919409499 \t650 комиссия возглавить философ и психолог карл штумпф в состав её войти самый разный человек чей профессия быть так или иначе связать с лошадь математика или психология врач ветеринар владелец цирк офицер кавалерия несколько школьный учитель математика и директор берлинский зоопарк\n",
      "\n",
      "0.16259964663 \t375 название популярный советский боевик пират xx век\n",
      "\n",
      "0.153022755113 \t552 xxii век править править вика текст в начало xxii век в клингонский общество повсеместно усилиться влияние класс воин\n",
      "\n",
      "0.151442905081 \t374 в сша один из крупный киностудия называться xx век фокс\n",
      "\n",
      "0.146690316487 \t1123 некоторый считать что дромеозаврид группа манираптор хороший классифицировать как птица а не динозавр 2\n",
      "\n",
      "0.14293979096 \t841 сам себя задавать темп работа\n",
      "\n",
      "0.142873850014 \t373 в советский союз и рф до 1995 год выходить журнал век xx и мир\n",
      "\n",
      "0.142724218122 \t303 сам применение вычислительный техника в два половина хх век изменить характер математический вычисление заставить математик отказаться от метод классический математический анализ и перейти к метод дискретный прикладной математика\n",
      "\n"
     ]
    }
   ],
   "source": [
    "serp_idf_1 = print_serp(rank_idf_1, query_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Искусственный язык для фантастической вселенной «Звёздный путь» создал профессиональный лингвист\n",
      "\n",
      "\n",
      "0.36514837167 \t234 звёздный путь англ\n",
      "\n",
      "0.363912671437 \t371 он известный как сценарист другой сериал в вселенная звёздный путь звёздный путь глубокий космос 9 1993 1999 звёздный путь в яджер 1995 2001\n",
      "\n",
      "0.350823207723 \t255 вселенная звёздный путь один из наиболее детально проработать вымышленный вселенная 1\n",
      "\n",
      "0.34749779421 \t374 он являться режиссёр и сценарист три фильм из серия звёздный путь звёздный путь ii гнев хан 1982 звёздный путь iv путешествие домой 1986 звёздный путь vi неоткрытый страна 1991\n",
      "\n",
      "0.338061701891 \t356 основный статья звёздный путь энтерпрайза звёздный путь энтерпра йз англ\n",
      "\n",
      "0.335410196625 \t1137 он создать специально для фильм лингвист марк окранд\n",
      "\n",
      "0.316227766017 \t4 2 звёздный путь 1\n",
      "\n",
      "0.310086836473 \t1 marc okrand mɑrk ˈoʊkrænd 3 июль 1948 американский лингвист известный как создатель язык для народ фантастический мир кинематограф сша клингонский вулканский и атлантский язык\n",
      "\n",
      "0.282842712475 \t434 звёздный путь исполниться 40 англ\n",
      "\n",
      "0.282842712475 \t1068 klingons ˈ k l ɪ ŋ ɒ n вымышленный инопланетный цивилизация гуманоид воин из научно фантастический вселенная звёздный путь 1\n",
      "\n",
      "0.271163072273 \t238 автор идея и основатель вселенная звёздный путь ведущий свой начало с выход на экран 8 сентябрь 1966 год сериал звёздный путь оригинальный сериал являться джина родденберри 1 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "serp_simple_2 = print_serp(rank_simple_2, query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Искусственный язык для фантастической вселенной «Звёздный путь» создал профессиональный лингвист\n",
      "\n",
      "\n",
      "0.349282738206 \t1137 он создать специально для фильм лингвист марк окранд\n",
      "\n",
      "0.288200424825 \t1 marc okrand mɑrk ˈoʊkrænd 3 июль 1948 американский лингвист известный как создатель язык для народ фантастический мир кинематограф сша клингонский вулканский и атлантский язык\n",
      "\n",
      "0.243760095689 \t255 вселенная звёздный путь один из наиболее детально проработать вымышленный вселенная 1\n",
      "\n",
      "0.222160411704 \t371 он известный как сценарист другой сериал в вселенная звёздный путь звёздный путь глубокий космос 9 1993 1999 звёздный путь в яджер 1995 2001\n",
      "\n",
      "0.215633043521 \t937 можно выделить следующий уровень профессиональный подготовка педагог существующий в настоящее время уровень профессиональный ориентация педагогический класс школа среднее профессиональный образование педагогический колледж высокий профессиональный образование высокий учебный заведение подготовка научно педагогический кадр для высокий профессиональный образование аспирантура докторантура\n",
      "\n",
      "0.208211762035 \t234 звёздный путь англ\n",
      "\n",
      "0.195002916722 \t1068 klingons ˈ k l ɪ ŋ ɒ n вымышленный инопланетный цивилизация гуманоид воин из научно фантастический вселенная звёздный путь 1\n",
      "\n",
      "0.191623322655 \t4 2 звёздный путь 1\n",
      "\n",
      "0.16219116977 \t238 автор идея и основатель вселенная звёздный путь ведущий свой начало с выход на экран 8 сентябрь 1966 год сериал звёздный путь оригинальный сериал являться джина родденберри 1 2\n",
      "\n",
      "0.161542086064 \t260 раса править править вика текст основный статья раса star trek вселенная звёздный путь англ\n",
      "\n",
      "0.159298619224 \t374 он являться режиссёр и сценарист три фильм из серия звёздный путь звёздный путь ii гнев хан 1982 звёздный путь iv путешествие домой 1986 звёздный путь vi неоткрытый страна 1991\n",
      "\n"
     ]
    }
   ],
   "source": [
    "serp_idf_2 = print_serp(rank_idf_2, query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: На территории России были обнаружены останки ниппонозаврa, амурозаврa,целурозаврa и другие виды динозавров.\n",
      "\n",
      "\n",
      "0.362738125055 \t467 первый и единственный неполный скелет быть обнаружить японец в 1934 год на территория больница в синегорск сахалин\n",
      "\n",
      "0.3 \t886 уметь слушать и слышать другой и иной мнение\n",
      "\n",
      "0.283980917124 \t141 транспорт тысячелетие основать на конный тяга быть на протяжение хх век заменить на грузовой автомобиль и автобус что стать возможный благодаря крупномасштабный эксплуатация ископаемое топливо\n",
      "\n",
      "0.282842712475 \t839 скульптура учитель на территория мади\n",
      "\n",
      "0.279751442472 \t529 среди вопрос на который он давать ответ быть не только такой как сколько быть 12 12 но и например если восьмой день месяц приходиться на вторник то какой день по счёт быть следующий пятница\n",
      "\n",
      "0.273861278753 \t20 для клингонский важно быть быть непохожий на привычный земной язык\n",
      "\n",
      "0.258198889747 \t521 результат исследование пфунгст быть принять научный сообщество и использоваться в эксперимент по интеллект животное и человек чтобы избежать влияние экспериментатор на испытуемый\n",
      "\n",
      "0.258198889747 \t605 орнитомимозавр немалоизвестный похожий на страус динозавр\n",
      "\n",
      "0.258198889747 \t892 брать на себя обязательство и ответственность\n",
      "\n",
      "0.253546276419 \t145 беспилотный космический зонд стать практический и относительно недорогой вид разведка и телекоммуникация\n",
      "\n",
      "0.253546276419 \t598 другой примитивный целурозавр орнитолестёс и целура последний изобразить на иллюстрация жить немного поздний процератозавр\n",
      "\n"
     ]
    }
   ],
   "source": [
    "serp_simple_3 = print_serp(rank_simple_3, query_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: На территории России были обнаружены останки ниппонозаврa, амурозаврa,целурозаврa и другие виды динозавров.\n",
      "\n",
      "\n",
      "0.286927874807 \t467 первый и единственный неполный скелет быть обнаружить японец в 1934 год на территория больница в синегорск сахалин\n",
      "\n",
      "0.24572800686 \t839 скульптура учитель на территория мади\n",
      "\n",
      "0.21050651436 \t659 единственный известный вид amurosaurus riabinini назвать в честь покойный палеонтолог анатолий рябинин который возглавить первый русский экспедиция 1916 и 1917 год для поиск окаменелый останки динозавр 4 5\n",
      "\n",
      "0.159383066239 \t885 помогать другой\n",
      "\n",
      "0.149710852665 \t605 орнитомимозавр немалоизвестный похожий на страус динозавр\n",
      "\n",
      "0.148047065197 \t155 пандемия а в конец век быть обнаружить новое вирусный заболевание спид который возникнуть в африка\n",
      "\n",
      "0.147064411445 \t656 amurosaurus родиться птицетазовый динозавр из подсемейство ламбеозаврин жить в конец меловой период верхний маастрихта 2 найти в россия в благовещенск 3\n",
      "\n",
      "0.143146067901 \t664 быть вскрыть лишь небольшой часть слой но 90 найти останки принадлежать ламбеозаврина такой как амурозавр в основное подросток остальной принадлежать другой таксон например гадрозаврид kerberosaurus\n",
      "\n",
      "0.141604093381 \t771 6 вид индивидуальный стиль педагогический деятельность 2\n",
      "\n",
      "0.133993126432 \t231 о другой значение смотреть\n",
      "\n",
      "0.1246960871 \t634 о четырёхкрылый динозавр и происхождение птица природа\n",
      "\n"
     ]
    }
   ],
   "source": [
    "serp_idf_3 = print_serp(rank_idf_3, query_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Размечаю истинную релевантность предложений для 1-го запроса: {doc_id:relevance}\n",
    "true_relevance_1 = {111:0, 71:0, 205:0, 1102:0, 824:0, 197:0, 838:0, 859:0, 156:0, 835:0, 115:0,\n",
    "                     549:1, 561:2, 205:0, 544:1, 198:0, 189:0, 607:0, 899:0, 196:0, 126:0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Размечаю истинную релевантность предложений для 2-го запроса: {doc_id:relevance}\n",
    "true_relevance_2 = {234:1, 371:1, 255:1, 374:1, 356:1, 1137:2, 4:1, 1:2, 434:1, 1068:2, 238:1,\n",
    "                   937:0, 260:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Размечаю истинную релевантность предложений для 3-го запроса: {doc_id:relevance}\n",
    "true_relevance_3 = {467:1, 886:0, 141:0, 839:0, 529:0, 20:0, 521:0, 605:1, 892:1, 145:0, 598:1,\n",
    "                   659:2, 885:0, 155:0, 656:2, 664:2, 771:0, 231:0, 634:1}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ideal_dcg(marks, N=10):\n",
    "    marks_sorted = sorted(marks, reverse=True)\n",
    "    ideal_dcg = 0\n",
    "    for i in range(N):\n",
    "        ideal_dcg += (1.0 * marks_sorted[i]) / np.log2(i + 2)\n",
    "    return ideal_dcg\n",
    "        \n",
    "def ndcg(marks, ideal_dcg, N=10):\n",
    "    dcg = 0\n",
    "    for i in range(N):\n",
    "        dcg += (1.0 * marks[i]) / np.log2(i + 2)\n",
    "    if ideal_dcg == 0:\n",
    "        return 1\n",
    "    \n",
    "    ndcg = dcg / float(ideal_dcg)\n",
    "    return ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rank_true_simple_1 = [true_relevance_1[doc_id] for doc_id in serp_simple_1]\n",
    "rank_true_idf_1 = [true_relevance_1[doc_id] for doc_id in serp_idf_1]\n",
    "rank_true_simple_2 = [true_relevance_2[doc_id] for doc_id in serp_simple_2]\n",
    "rank_true_idf_2 = [true_relevance_2[doc_id] for doc_id in serp_idf_2]\n",
    "rank_true_simple_3 = [true_relevance_3[doc_id] for doc_id in serp_simple_3]\n",
    "rank_true_idf_3 = [true_relevance_3[doc_id] for doc_id in serp_idf_3]\n",
    "\n",
    "rank_true_1 = [true_relevance_1[doc_id] for doc_id in true_relevance_1.keys()]\n",
    "rank_true_2 = [true_relevance_2[doc_id] for doc_id in true_relevance_2.keys()]\n",
    "rank_true_3 = [true_relevance_3[doc_id] for doc_id in true_relevance_3.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ideal NDCG for query 1: 3.13092975357\n",
      "Ideal NDCG for query 2: 6.67448909166\n",
      "Ideal NDCG for query 3: 6.08439426968\n"
     ]
    }
   ],
   "source": [
    "ideal_dcg_1 = ideal_dcg(rank_true_1)\n",
    "ideal_dcg_2 = ideal_dcg(rank_true_2)\n",
    "ideal_dcg_3 = ideal_dcg(rank_true_3)\n",
    "\n",
    "print \"Ideal NDCG for query 1:\", ideal_dcg_1\n",
    "print \"Ideal NDCG for query 2:\", ideal_dcg_2\n",
    "print \"Ideal NDCG for query 3:\", ideal_dcg_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print len(rank_true_simple_2)\n",
    "print len(serp_simple_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG for simple system, query 1: 0.0\n",
      "NDCG for simple system, query 2: 0.824676788397\n",
      "NDCG for simple system, query 3: 0.265678849989\n",
      "NDCG for system with idf, query 1: 0.859979711185\n",
      "NDCG for system with idf, query 2: 0.91706938669\n",
      "NDCG for system with idf, query 3: 0.605557277219\n"
     ]
    }
   ],
   "source": [
    "ndcg_simple_1 = ndcg(rank_true_simple_1, ideal_dcg_1)\n",
    "ndcg_idf_1 = ndcg(rank_true_idf_1, ideal_dcg_1)\n",
    "ndcg_simple_2 = ndcg(rank_true_simple_2, ideal_dcg_2)\n",
    "ndcg_idf_2 = ndcg(rank_true_idf_2, ideal_dcg_2)\n",
    "ndcg_simple_3 = ndcg(rank_true_simple_3, ideal_dcg_3)\n",
    "ndcg_idf_3 = ndcg(rank_true_idf_3, ideal_dcg_3)\n",
    "\n",
    "print \"NDCG for simple system, query 1:\", ndcg_simple_1\n",
    "print \"NDCG for simple system, query 2:\", ndcg_simple_2\n",
    "print \"NDCG for simple system, query 3:\", ndcg_simple_3\n",
    "\n",
    "print \"NDCG for system with idf, query 1:\", ndcg_idf_1\n",
    "print \"NDCG for system with idf, query 2:\", ndcg_idf_2\n",
    "print \"NDCG for system with idf, query 3:\", ndcg_idf_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_ndcg_simple = np.mean([ndcg_simple_1, ndcg_simple_2, ndcg_simple_3])\n",
    "mean_ndcg_idf = np.mean([ndcg_idf_1, ndcg_idf_2, ndcg_idf_3])\n",
    "\n",
    "print \"Mean NDCG for simple system:\", mean_ndcg_simple\n",
    "print \"Mean NDCG for system with idf:\", mean_ndcg_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Языковая модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Размечаю истинную релевантность предложений для 1-го запроса: {doc_id:relevance}\n",
    "true_relevance_1 = {135:0, 40:0, 54:0, 869:0, 744:2, 753:1, 770:2, 14:0, 148:0, 547:0, 15:0} \n",
    "#Размечаю истинную релевантность предложений для 2-го запроса: {doc_id:relevance}\n",
    "true_relevance_2 = {420:1, 417:1, 982:0, 433:1, 666:2, 284:1, 461:1, 513:1, 301:1, 338:0, 348:0} \n",
    "#Размечаю истинную релевантность предложений для 3-го запроса: {doc_id:relevance}\n",
    "true_relevance_3 = {738:0, 188:1, 619:2, 993:0, 84:0, 678:0, 770:0, 61:0, 177:1, 730:0, 995:0} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в начало xx век немецкий учитель математика сам тот не желать научить лошадь считать\n",
      "3502\n",
      "в 0.0383148117432 1\n",
      "начало 0.000580527450655 0\n",
      "xx 0.000829324929507 0\n",
      "век 0.00481008459114 0\n",
      "немецкий 0.000331729971803 0\n",
      "учитель 0.00348316470393 0\n",
      "математика 0.000497594957704 0\n",
      "сам 0.000663459943606 0\n",
      "тот 0.00232210980262 0\n",
      "не 0.0053906120418 0\n",
      "лошадь 0.000414662464754 0\n",
      "считать 0.000248797478852 0\n",
      "искусственный язык для фантастический вселенная звёздный путь создать профессиональный лингвист\n",
      "3502\n",
      "искусственный 8.29324929507e-05 0\n",
      "язык 0.00298556974623 0\n",
      "для 0.00281970476033 0\n",
      "фантастический 0.000331729971803 0\n",
      "вселенная 0.00116105490131 0\n",
      "звёздный 0.00663459943606 0\n",
      "путь 0.00680046442196 0\n",
      "создать 0.00140985238016 0\n",
      "профессиональный 0.000995189915409 0\n",
      "лингвист 0.000248797478852 0\n",
      "на территория россия быть обнаружить останки ниппонозаврa амурозаврa целурозаврa и другой вид динозавр\n",
      "3502\n",
      "на 0.0113617515343 0\n",
      "территория 0.000165864985901 0\n",
      "россия 0.00107812240836 0\n",
      "быть 0.00754685685852 0\n",
      "обнаружить 0.000331729971803 0\n",
      "останки 0.000248797478852 0\n",
      "и 0.0356609719688 1\n",
      "другой 0.00232210980262 0\n",
      "вид 0.000829324929507 0\n",
      "динозавр 0.000995189915409 0\n"
     ]
    }
   ],
   "source": [
    "rank_lang_1 = collection.lang_model_ranking(query=query_1)\n",
    "rank_lang_2 = collection.lang_model_ranking(query=query_2)\n",
    "rank_lang_3 = collection.lang_model_ranking(query=query_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: В начале XX века немецкий учитель математики, сам того не желая, научил лошадь считать.\n",
      "\n",
      "\n",
      "4.91736606402 \t135 население планета продолжать увеличиваться взрывной темп от 1 миллиард в 1820 до 2 миллиард в 1930 3 миллиард в 1960 4 миллиард в 1974 5 миллиард в 1988 6 миллиард в 2000 7 миллиард в 2012\n",
      "\n",
      "4.21736606402 \t40 экономический и политический потрясение европа в один половина век привести к возникновение тоталитарный идеология несколько тип в европа фашизм в россия коммунизм а в германия после великий депрессия в 30 е год нацизм\n",
      "\n",
      "4.21736606402 \t54 в начало век популярный в сша стать блюз и джаз который сохранять свой господство в музыка до появление рок наш ролл в 1950 х год\n",
      "\n",
      "4.21736606402 \t869 в многий страна в тот число и в россия в 21 век наблюдаться тенденция к снижение престижность педагогический профессия и как следствие недооценённость учительский труд\n",
      "\n",
      "3.51736606402 \t744 через какой то время статья о ганс быть напечатать в американский газета new york times после что удивительный лошадь получить относительно широкий известность в весь мир и привлечь к себя внимание в тот число учёный\n",
      "\n",
      "3.51736606402 \t753 комиссия возглавить философ и психолог карл штумпф в состав её войти самый разный человек чей профессия быть так или иначе связать с лошадь математика или психология врач ветеринар владелец цирк офицер кавалерия несколько школьный учитель математика и директор берлинский зоопарк\n",
      "\n",
      "3.51736606402 \t770 другой слово ганс быть действительно феноменально умный лошадь и прекрасно понимать что от он хотеть но конечно ни математика ни немецкий язык он не знать и не понимать\n",
      "\n",
      "3.51736606402 \t14 содержание скрыть 1 основной событие 2 главное изобретение 3 использование сочетание xx век в название 4 двадцать век в искусство 5 сантиметр\n",
      "\n",
      "3.51736606402 \t148 также править править вика текст в викитека есть текст по тема документ xx век xx век хронология изобретение\n",
      "\n",
      "3.51736606402 \t547 xxii век править править вика текст в начало xxii век в клингонский общество повсеместно усилиться влияние класс воин\n",
      "\n",
      "3.51736606402 \t15 также 6 примечание основной событие править править вика текст xx век принести серьёзный сдвиг в мировоззрение в результат изменение в экономика политика идеология культура наука техника и медицина\n",
      "\n"
     ]
    }
   ],
   "source": [
    "serp_lang_1 = print_serp(rank_lang_1, query_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Искусственный язык для фантастической вселенной «Звёздный путь» создал профессиональный лингвист\n",
      "\n",
      "\n",
      "5.60704096865 \t420 он являться режиссёр и сценарист три фильм из серия звёздный путь звёздный путь ii гнев хан 1982 звёздный путь iv путешествие домой 1986 звёздный путь vi неоткрытый страна 1991\n",
      "\n",
      "4.90704096865 \t417 он известный как сценарист другой сериал в вселенная звёздный путь звёздный путь глубокий космос 9 1993 1999 звёздный путь в яджер 1995 2001\n",
      "\n",
      "4.20704096865 \t982 можно выделить следующий уровень профессиональный подготовка педагог существующий в настоящее время уровень профессиональный ориентация педагогический класс школа средний профессиональный образование педагогический колледж высокий профессиональный образование высокий учебный заведение подготовка научно педагогический кадр для высокий профессиональный образование аспирантура докторантура\n",
      "\n",
      "4.20704096865 \t433 пейн звёздный путь человек и бог править править вика текст основный статья звёздный путь человек и бог особняком стоить полнометражный фанфик звёздный путь человек и бог star trek of gods and men 2007\n",
      "\n",
      "3.50704096865 \t666 marc okrand mɑrk ˈoʊkrænd 3 июль 1948 американский лингвист известный как создатель язык для народ фантастический мир кинематограф сша клингонский вулканский и атлантский язык\n",
      "\n",
      "3.50704096865 \t284 автор идея и основатель вселенная звёздный путь ведущий свой начать с выход на экран 8 сентябрь 1966 год сериал звёздный путь оригинальный сериал являться джина родденберри 1 2\n",
      "\n",
      "3.50704096865 \t461 сериал и фильм звёздный путь в хронологический порядок событие править править вика текст хронологический порядок событие в вселенная звёздный путь отличаться от порядок выход на экран фильм и сериал\n",
      "\n",
      "2.80704096865 \t513 klingons ˈ k l ɪ ŋ ɒ n вымышленный инопланетный цивилизация гуманоид воин из научно фантастический вселенная звёздный путь 1\n",
      "\n",
      "2.80704096865 \t301 вселенная звёздный путь один из наиболее детально проработать вымышленный вселенная 1\n",
      "\n",
      "2.80704096865 \t338 оригинальный сериал 1966 1969 править править вика текст основный статья звёздный путь оригинальный сериал команда звездолёт энтерпрайза звёздный путь оригинальный сериал англ\n",
      "\n",
      "2.80704096865 \t348 анимационный сериал 1973 1974 править править вика текст основный статья звёздный путь анимационный сериал звёздный путь анимационный сериал англ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "serp_lang_2 = print_serp(rank_lang_2, query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: На территории России были обнаружены останки ниппонозаврa, амурозаврa,целурозаврa и другие виды динозавров.\n",
      "\n",
      "\n",
      "4.21816221596 \t738 среди вопрос на который он давать ответ быть не только такой как сколько быть 12 12 но и например если восемь день месяц приходиться на вторник то какой днём по счёт быть следующий пятница\n",
      "\n",
      "3.51816221596 \t188 большинство другой известный ламбеозаврин иметь полый гребень на верхний часть череп и хотя костя который составлять такой гребень неизвестный у это динозавр костя крышка череп видоизменяться чтобы поддерживать такой гребень поэтому можно предположить что амурозавр быть также с гребень\n",
      "\n",
      "3.51816221596 \t619 один и единственный неполный скелет быть обнаружить японец в 1934 год на территория больница в синегорск сахалин\n",
      "\n",
      "3.51816221596 \t993 например никогда и никуда не опаздывать никогда и никто не отвечать односложно да нет искать другой форма ответ никогда и никто не отказывать в помощь и том\n",
      "\n",
      "3.51816221596 \t84 транспорт тысячелетие основать на конный тяга быть на протяжение хх век заменить на грузовой автомобиль и автобус что стать возможный благодаря крупномасштабный эксплуатация ископаемое топливо\n",
      "\n",
      "3.51816221596 \t678 самый один он действие в рамка сотрудничество быть дубляж диалог на вулканский язык в фильм звёздный путь гнев хан 1982 поскольку на тот момент этот диалог уже быть снятой на английский язык\n",
      "\n",
      "2.81816221596 \t770 другой слово ганс быть действительно феноменально умный лошадь и прекрасно понимать что от он хотеть но конечно ни математика ни немецкий язык он не знать и не понимать\n",
      "\n",
      "2.81816221596 \t61 начать свой деятельность в стиль модернизм архитектор хх век после многочисленный потрясение и разрушение мировой война а также ввиду развитие строительный индустрия возникнуть на основа применение стандартный железобетонный изделие вынудить быть отказаться от украшательство и перейти к упрощение форма\n",
      "\n",
      "2.81816221596 \t177 единственный известный вид amurosaurus riabinini назвать в честь покойный палеонтолог анатолий рябинин который возглавить один русский экспедиция 1916 и 1917 год для поиск окаменелый останки динозавр 4 5\n",
      "\n",
      "2.81816221596 \t730 результат исследование пфунгст быть принять научный сообщество и использоваться в эксперимент по интеллект животное и человек чтобы избежать влияние экспериментатор на испытуемый\n",
      "\n",
      "2.81816221596 \t995 наряду с программа самовоспитание можно составить и план работа над себя план максимум на большой отрезка время и план минимум на день неделя месяц\n",
      "\n"
     ]
    }
   ],
   "source": [
    "serp_lang_3 = print_serp(rank_lang_3, query_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ideal NDCG for query 1: 3.76185950714\n",
      "Ideal NDCG for query 2: 4.95346451611\n",
      "Ideal NDCG for query 3: 3.13092975357\n"
     ]
    }
   ],
   "source": [
    "rank_true_1 = [true_relevance_1[doc_id] for doc_id in true_relevance_1.keys()]\n",
    "rank_true_2 = [true_relevance_2[doc_id] for doc_id in true_relevance_2.keys()]\n",
    "rank_true_3 = [true_relevance_3[doc_id] for doc_id in true_relevance_3.keys()]\n",
    "\n",
    "ideal_dcg_1 = ideal_dcg(rank_true_1)\n",
    "ideal_dcg_2 = ideal_dcg(rank_true_2)\n",
    "ideal_dcg_3 = ideal_dcg(rank_true_3)\n",
    "\n",
    "print \"Ideal NDCG for query 1:\", ideal_dcg_1\n",
    "print \"Ideal NDCG for query 2:\", ideal_dcg_2\n",
    "print \"Ideal NDCG for query 3:\", ideal_dcg_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_true_lang_1 = [true_relevance_1[doc_id] for doc_id in serp_lang_1]\n",
    "rank_true_lang_2 = [true_relevance_2[doc_id] for doc_id in serp_lang_2]\n",
    "rank_true_lang_3 = [true_relevance_3[doc_id] for doc_id in serp_lang_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG for language model, query 1: 0.477577502518\n",
      "NDCG for language_model, query 2: 0.836050668283\n",
      "NDCG for language_model, query 3: 0.617056242489\n"
     ]
    }
   ],
   "source": [
    "ndcg_lang_1 = ndcg(rank_true_lang_1, ideal_dcg_1)\n",
    "ndcg_lang_2 = ndcg(rank_true_lang_2, ideal_dcg_2)\n",
    "ndcg_lang_3 = ndcg(rank_true_lang_3, ideal_dcg_3)\n",
    "\n",
    "print \"NDCG for language model, query 1:\", ndcg_lang_1\n",
    "print \"NDCG for language model, query 2:\", ndcg_lang_2\n",
    "print \"NDCG for language model, query 3:\", ndcg_lang_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mean NDCG for language model: 0.643561471096\n"
     ]
    }
   ],
   "source": [
    "mean_ndcg_lang = np.mean([ndcg_lang_1, ndcg_lang_2, ndcg_lang_3])\n",
    "print \"Mean NDCG for language model:\", mean_ndcg_lang"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
